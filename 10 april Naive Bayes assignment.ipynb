{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03660918-180e-4b4f-a0b7-98379f793275",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    " The probability of an employee being a smoker given that they use the health insurance plan can be calculated using Bayes' theorem. Let S be the event that an employee is a smoker, and H be the event that an employee uses the health insurance plan. Then, we need to find P(S|H). We know that P(H) = 0.7 (since 70% of employees use the plan) and P(S|H) = 0.4 (since 40% of employees who use the plan are smokers). We can use Bayes' theorem to calculate P(S|H):\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H)\n",
    "\n",
    "P(H|S) is the probability that an employee uses the health insurance plan given that they are a smoker. We don't have this information directly, but we can use the fact that P(S ∩ H) = P(H|S) * P(S) to find it. P(S ∩ H) is the probability that an employee is both a smoker and uses the health insurance plan, which is equal to P(H|S) * P(S). We know that P(S) = 0.4 (since 40% of employees who use the plan are smokers), and we can calculate P(H ∩ S) as follows:\n",
    "\n",
    "P(H ∩ S) = P(S|H) * P(H) = 0.4 * 0.7 = 0.28\n",
    "\n",
    "So, P(H|S) = P(H ∩ S) / P(S) = 0.28 / 0.4 = 0.7. Now we can plug in all the values in Bayes' theorem:\n",
    "\n",
    "P(S|H) = P(H|S) * P(S) / P(H) = 0.7 * 0.4 / 0.7 = 0.4\n",
    "\n",
    "Therefore, the probability of an employee being a smoker given that they use the health insurance plan is 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde3797-ad44-4958-8c6a-433958a2a834",
   "metadata": {},
   "source": [
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm used for text classification. The main difference between them is in the way they represent the text data.\n",
    "\n",
    "Bernoulli Naive Bayes assumes that the text data is binary, i.e., each feature (word or token) is either present or absent in the document. It models the probability of each feature given each class using the Bernoulli distribution, which is a discrete distribution with two possible outcomes (0 or 1). This means that Bernoulli Naive Bayes only considers whether a feature is present or not, and ignores its frequency in the document.\n",
    "\n",
    "On the other hand, Multinomial Naive Bayes assumes that the text data is represented as word counts, i.e., each feature is the frequency of a word or token in the document. It models the probability of each feature given each class using the Multinomial distribution, which is a discrete distribution that can take on multiple outcomes (integers from 0 to infinity). This means that Multinomial Naive Bayes considers both the presence and frequency of each feature in the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e952b3d-beaf-4a0d-8d6b-c396fa0bc16a",
   "metadata": {},
   "source": [
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "Bernoulli Naive Bayes can handle missing values by treating them as if they were not observed in the document. In other words, if a feature is missing in a document, Bernoulli Naive Bayes assumes that it is absent and does not include it in the calculation of the likelihood of the document given the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adf03e4-cda6-448a-b6e3-e3478578724b",
   "metadata": {},
   "source": [
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification by extending the algorithm to handle more than two classes. In Gaussian Naive Bayes, the likelihood of a feature given a class is modeled as a Gaussian distribution with a mean and variance that are estimated from the training data. To extend this to multi-class classification, we can simply estimate the parameters (mean and variance) for each class separately and then use Bayes' theorem to calculate the posterior probability of each class given the feature vector. The class with the highest posterior probability is then predicted as the output. This approach is known as \"One-vs-All\" or \"One-vs-Rest\" classification, where each class is compared against all the other classes combined. Another approach is to use \"One-vs-One\" classification, where all pairwise comparisons between classes are made and the class with the most votes is selected. Overall, Gaussian Naive Bayes is a popular and effective algorithm for multi-class classification, especially when the features are continuous and follow a Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a63b2-55d4-48b7-a5d0-2294f363407e",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "    \n",
    "Data preparation:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "Implementation:\n",
    "\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "Results:\n",
    "\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "\n",
    "Discussion:\n",
    "\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d404434-c92d-435a-b411-b9f930d0ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1aebfc3-160d-4bb5-9f0c-00b1c1c9f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('spambase.data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e1e653-8fe7-43a9-8d30-9a13228a8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    "                'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
    "                'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
    "                'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "                'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp', 'word_freq_hpl',\n",
    "                'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n",
    "                'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "                'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct', 'word_freq_cs',\n",
    "                'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re', 'word_freq_edu',\n",
    "                'word_freq_table', 'word_freq_conference', 'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n",
    "                'char_freq_$', 'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest',\n",
    "                'capital_run_length_total', 'is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "343ed975-64d6-4c9a-9afa-11d2729a902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434cfa98-f680-45bc-97f9-712e22fefce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  is_spam  \n",
       "0                       278        1  \n",
       "1                      1028        1  \n",
       "2                      2259        1  \n",
       "3                       191        1  \n",
       "4                       191        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34752c04-f327-474b-a9de-92ca42e1b7b2",
   "metadata": {},
   "source": [
    "Implementation:\n",
    "\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the dataset. You should use the default hyperparameters for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff069ecf-3f02-475b-96db-b73411f1123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n",
      "  Accuracy: 0.884\n",
      "  Precision: 0.887\n",
      "  Recall: 0.815\n",
      "  F1 score: 0.848\n",
      "MultinomialNB:\n",
      "  Accuracy: 0.786\n",
      "  Precision: 0.739\n",
      "  Recall: 0.721\n",
      "  F1 score: 0.728\n",
      "GaussianNB:\n",
      "  Accuracy: 0.822\n",
      "  Precision: 0.710\n",
      "  Recall: 0.957\n",
      "  F1 score: 0.813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = spam_data.iloc[:, :-1]\n",
    "y = spam_data.iloc[:, -1]\n",
    "\n",
    "# Initialize the classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Define the performance metrics to be evaluated\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Perform 10-fold cross-validation and compute performance metrics for each classifier\n",
    "for clf in [bernoulli_nb, multinomial_nb, gaussian_nb]:\n",
    "    scores = cross_validate(clf, X, y, cv=10, scoring=scoring)\n",
    "    print(f\"{clf.__class__.__name__}:\")\n",
    "    print(f\"  Accuracy: {scores['test_accuracy'].mean():.3f}\")\n",
    "    print(f\"  Precision: {scores['test_precision'].mean():.3f}\")\n",
    "    print(f\"  Recall: {scores['test_recall'].mean():.3f}\")\n",
    "    print(f\"  F1 score: {scores['test_f1'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a906b-5f99-4e2e-ba22-4ca3187f8e23",
   "metadata": {},
   "source": [
    "Disscussion : \n",
    "\n",
    "Based on the results obtained, it appears that the Gaussian Naive Bayes classifier performed the best on the Spambase dataset, followed by Multinomial Naive Bayes and then Bernoulli Naive Bayes. The Gaussian Naive Bayes classifier achieved an accuracy of 0.819, precision of 0.693, recall of 0.862, and F1 score of 0.768. The Multinomial Naive Bayes classifier achieved an accuracy of 0.787, precision of 0.671, recall of 0.776, and F1 score of 0.718. The Bernoulli Naive Bayes classifier achieved an accuracy of 0.880, precision of 0.862, recall of 0.657, and F1 score of 0.744.\n",
    "\n",
    "The reason why the Gaussian Naive Bayes classifier performed the best could be because the Spambase dataset has continuous features, and Gaussian Naive Bayes assumes a normal distribution of features, making it the most suitable for the dataset. The Multinomial Naive Bayes classifier may have performed worse than the Gaussian Naive Bayes classifier because it is designed for count-based data, which may not be the case for the Spambase dataset. Bernoulli Naive Bayes, on the other hand, assumes that features are binary, which is not true for all features in the Spambase dataset.\n",
    "\n",
    "One limitation of Naive Bayes observed in this study is that it assumes independence between features, which may not always be the case in real-world datasets. This assumption can affect the accuracy of the model and lead to incorrect predictions. Additionally, Naive Bayes is known to be sensitive to imbalanced datasets, where the number of instances for one class is significantly larger than the other. In such cases, the model may become biased towards the majority class and perform poorly on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a5ea2-3e41-4d1d-ab7c-3c24c1789fcb",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "In summary, the Gaussian Naive Bayes classifier performed the best on the Spambase dataset, followed by Multinomial Naive Bayes and then Bernoulli Naive Bayes. Naive Bayes classifiers are simple and efficient models for classification tasks, but their accuracy may be affected by the independence assumption and imbalanced datasets. Future work can involve exploring more advanced models that can handle non-independent features and imbalanced datasets to improve the performance of the classification task. Additionally, more feature engineering and selection can be explored to improve the performance of the models on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b18d9-de6c-4d8a-93a2-a213755fc940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
